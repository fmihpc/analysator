# This workflow will install Python dependencies and analysator, run the analysator testpackage based on git diff and compare the images 
name: Turso compare selectively images

on:
  pull_request:
    branches: [ master, dev]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}


jobs:

  turso_system:
        if: github.repository_owner == 'fmihpc'
        runs-on: carrington
        timeout-minutes: 120
        strategy:
          fail-fast: false
          max-parallel: 2
          matrix:
            extras: ["testpackage"]
        steps:
        - uses: actions/checkout@v4
          timeout-minutes: 5
          with:
            fetch-depth: 0
        - name: Install uv
          uses: astral-sh/setup-uv@v6
          timeout-minutes: 5
        - name: Install dependencies
          timeout-minutes: 5
          run: |
            export TMPDIR=$RUNNER_TEMP
            export UV_LINK_MODE=copy
            module purge
            module load Python/3.10.4-GCCcore-11.3.0
            uv venv CI_env
            . CI_env/bin/activate
            uv pip install --editable ../analysator[${{ matrix.extras }}]
        - name: Produce plots
          id: run_cl
          run: |
            export TMPDIR=$RUNNER_TEMP
            module purge
            module load Python/3.10.4-GCCcore-11.3.0
            verf_loc="/wrk-kappa/group/spacephysics/analysator/CI/verification_sets"
            verfset=$(ls -lth $verf_loc | grep ^d | head -n1 | grep -Po '\w+$')
            if [[ -f $verf_loc/$verfset/.lockfile ]]; then 
              echo -e ".lockfile found in $verf_loc/$verfset, not running test, as the verification set generation is likely still ongoing\n Check ongoing actions and/or re-run verification set generation."
              exit 1
            fi
            export DIFFRESULT=$(python ./testpackage/testpackage_get_diff.py ${{ github.base_ref }})
            if [[ -f diff_log.txt ]]; then
              cat diff_log.txt
            fi
            echo "DIFFRESULT=$DIFFRESULT" >> $GITHUB_OUTPUT
            echo "Running $DIFFRESULT"
            MAX_ARRAY=14
            TOTAL_TESTS=$(ls ./testpackage/testpackage_definitions/ | wc -l) 
            if [[ $DIFFRESULT && $DIFFRESULT != "pass" ]]; then
              NUM_OF_TESTS=$($DIFFRESULT | sed -e 's/ /\n/g' | wc -l)
              ARRAY_SIZE=$(( NUM_OF_TESTS*(MAX_ARRAY+TOTAL_TESTS-1)/TOTAL_TESTS )) #Rounding up 
            else
              ARRAY_SIZE=$MAX_ARRAY
            fi
            sbatch -W -o testpackage_run.txt --array=1-$ARRAY_SIZE --job-name gen_plots ./testpackage/run_testpackage_workflow.sh $DIFFRESULT > jobid.txt
            export JOBID=$(grep -Po '\d+' jobid.txt)
            export SACCT_LOG=$(sacct -j $JOBID -o job,state,node | grep FAILED) 
            if [[ $SACCT_LOG ]]; then
              echo "Some job failed on a node"
              echo "$SACCT_LOG" 
              exit 1
            fi
            cat testpackage_run.txt
            . CI_env/bin/activate
            python ./testpackage/testpackage_get_job_error.py testpackage_run.txt
            
        - name: Comparing plotted data
          run: |
            export TMPDIR=$RUNNER_TEMP
            module load Python/3.10.4-GCCcore-11.3.0
            . CI_env/bin/activate
            sbatch -W -o "testpackage_compare.txt" ./testpackage/run_compare.sh ${{ steps.run_cl.outputs.DIFFRESULT }}
            cat testpackage_compare.txt
            python ./testpackage/testpackage_get_job_error.py testpackage_compare.txt
        - name: scancel dangling job upon cancellation
          if: cancelled()
          run: |
            scancel ${{ steps.run_cl.outputs.SLURM_JOB_ID }}
            
  
